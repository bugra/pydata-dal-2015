{
 "metadata": {
  "name": "",
  "signature": "sha256:2ba734dabe81e3a9f73cf6d636f068c05e6e3d3c304ba780de3be130687fdfb7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you have more data than you could fit into the memory of your machine, chances are that you would want to use something different than `fit` as `fit` needs to load the data into memory once to train the classifier. However, some of the classifiers  support `partial_fit` in Scikit-Learn which does not require data to load into memory. You could train you data in batches so that you could process it as you fit the data into the memory of the machine. Further, if you want to train further your classifier with new data, you do not have to retrain the whole classifier, but rather feed the new data into the classifier by calling `partial_fit` function. By doing so, you have a way of improving the classifier with available new data rather than going through loading the data once into the memory with the old data that you trained the classifier already."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "My suggestion is that you would divide the data into batches in such a way that size of the batches would be close to the memory of the machine as there is an overhead of function call to model. The smaller you call `partial_fit` is the faster you train the model. In these cases, efficiency is not just bound to the data size but how you divide the data into batches. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import os\n",
      "import pandas as pd\n",
      "import seaborn as sns\n",
      "from sklearn import linear_model\n",
      "from sklearn import naive_bayes\n",
      "from sklearn import preprocessing\n",
      "\n",
      "DATA_DIR = 'data'\n",
      "BANK_DIR = os.path.join(DATA_DIR, 'bank')\n",
      "BANK_FULL_PATH = os.path.join(BANK_DIR, 'bank-full.csv')\n",
      "EXPLANATION_PATH = os.path.join(BANK_DIR, 'bank-names.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(EXPLANATION_PATH) as f:\n",
      "    explanation = f.readlines()\n",
      "explanation = '\\n'.join(explanation)    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(explanation)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Citation Request:\r\n",
        "\n",
        "  This dataset is public available for research. The details are described in [Moro et al., 2011]. \r\n",
        "\n",
        "  Please include this citation if you plan to use this database:\r\n",
        "\n",
        "\r\n",
        "\n",
        "  [Moro et al., 2011] S. Moro, R. Laureano and P. Cortez. Using Data Mining for Bank Direct Marketing: An Application of the CRISP-DM Methodology. \r\n",
        "\n",
        "  In P. Novais et al. (Eds.), Proceedings of the European Simulation and Modelling Conference - ESM'2011, pp. 117-121, Guimar\u00e3es, Portugal, October, 2011. EUROSIS.\r\n",
        "\n",
        "\r\n",
        "\n",
        "  Available at: [pdf] http://hdl.handle.net/1822/14838\r\n",
        "\n",
        "                [bib] http://www3.dsi.uminho.pt/pcortez/bib/2011-esm-1.txt\r\n",
        "\n",
        "\r\n",
        "\n",
        "1. Title: Bank Marketing\r\n",
        "\n",
        "\r\n",
        "\n",
        "2. Sources\r\n",
        "\n",
        "   Created by: Paulo Cortez (Univ. Minho) and S\u00e9rgio Moro (ISCTE-IUL) @ 2012\r\n",
        "\n",
        "   \r\n",
        "\n",
        "3. Past Usage:\r\n",
        "\n",
        "\r\n",
        "\n",
        "  The full dataset was described and analyzed in:\r\n",
        "\n",
        "\r\n",
        "\n",
        "  S. Moro, R. Laureano and P. Cortez. Using Data Mining for Bank Direct Marketing: An Application of the CRISP-DM Methodology. \r\n",
        "\n",
        "  In P. Novais et al. (Eds.), Proceedings of the European Simulation and Modelling Conference - ESM'2011, pp. 117-121, Guimar\u00e3es, \r\n",
        "\n",
        "  Portugal, October, 2011. EUROSIS.\r\n",
        "\n",
        "\r\n",
        "\n",
        "4. Relevant Information:\r\n",
        "\n",
        "\r\n",
        "\n",
        "   The data is related with direct marketing campaigns of a Portuguese banking institution. \r\n",
        "\n",
        "   The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, \r\n",
        "\n",
        "   in order to access if the product (bank term deposit) would be (or not) subscribed. \r\n",
        "\n",
        "\r\n",
        "\n",
        "   There are two datasets: \r\n",
        "\n",
        "      1) bank-full.csv with all examples, ordered by date (from May 2008 to November 2010).\r\n",
        "\n",
        "      2) bank.csv with 10% of the examples (4521), randomly selected from bank-full.csv.\r\n",
        "\n",
        "   The smallest dataset is provided to test more computationally demanding machine learning algorithms (e.g. SVM).\r\n",
        "\n",
        "\r\n",
        "\n",
        "   The classification goal is to predict if the client will subscribe a term deposit (variable y).\r\n",
        "\n",
        "\r\n",
        "\n",
        "5. Number of Instances: 45211 for bank-full.csv (4521 for bank.csv)\r\n",
        "\n",
        "\r\n",
        "\n",
        "6. Number of Attributes: 16 + output attribute.\r\n",
        "\n",
        "\r\n",
        "\n",
        "7. Attribute information:\r\n",
        "\n",
        "\r\n",
        "\n",
        "   For more information, read [Moro et al., 2011].\r\n",
        "\n",
        "\r\n",
        "\n",
        "   Input variables:\r\n",
        "\n",
        "   # bank client data:\r\n",
        "\n",
        "   1 - age (numeric)\r\n",
        "\n",
        "   2 - job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\",\"student\",\r\n",
        "\n",
        "                                       \"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\") \r\n",
        "\n",
        "   3 - marital : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\" means divorced or widowed)\r\n",
        "\n",
        "   4 - education (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\")\r\n",
        "\n",
        "   5 - default: has credit in default? (binary: \"yes\",\"no\")\r\n",
        "\n",
        "   6 - balance: average yearly balance, in euros (numeric) \r\n",
        "\n",
        "   7 - housing: has housing loan? (binary: \"yes\",\"no\")\r\n",
        "\n",
        "   8 - loan: has personal loan? (binary: \"yes\",\"no\")\r\n",
        "\n",
        "   # related with the last contact of the current campaign:\r\n",
        "\n",
        "   9 - contact: contact communication type (categorical: \"unknown\",\"telephone\",\"cellular\") \r\n",
        "\n",
        "  10 - day: last contact day of the month (numeric)\r\n",
        "\n",
        "  11 - month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\r\n",
        "\n",
        "  12 - duration: last contact duration, in seconds (numeric)\r\n",
        "\n",
        "   # other attributes:\r\n",
        "\n",
        "  13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\r\n",
        "\n",
        "  14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)\r\n",
        "\n",
        "  15 - previous: number of contacts performed before this campaign and for this client (numeric)\r\n",
        "\n",
        "  16 - poutcome: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\")\r\n",
        "\n",
        "\r\n",
        "\n",
        "  Output variable (desired target):\r\n",
        "\n",
        "  17 - y - has the client subscribed a term deposit? (binary: \"yes\",\"no\")\r\n",
        "\n",
        "\r\n",
        "\n",
        "8. Missing Attribute Values: None\r\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv(BANK_FULL_PATH, delimiter=';')\n",
      "label_encoder = preprocessing.LabelEncoder()\n",
      "for field in ('job', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome', 'marital'):\n",
      "    df[field] = label_encoder.fit_transform(df[field])\n",
      "    \n",
      "df['y'] = df.y == 'yes'\n",
      "y = df.y.apply(lambda k: int(k))\n",
      "del df['y']\n",
      "\n",
      "standard_scaler = preprocessing.StandardScaler()\n",
      "for field in df.columns:\n",
      "    df[field] = standard_scaler.fit_transform(df[field])\n",
      "    \n",
      "X = df.as_matrix()\n",
      "print(X.shape, y.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "((45211, 16), (45211,))\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Here are the classifiers that we could use for out-of-core learning"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- `sklearn.naive_bayes.MultinomialNB`\n",
      "- `sklearn.naive_bayes.BernoulliNB`\n",
      "- `sklearn.linear_model.Perceptron`\n",
      "- `sklearn.linear_model.SGDClassifier`\n",
      "- `sklearn.linear_model.PassiveAggressiveClassifier`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "incremental_learners = (\n",
      "                        naive_bayes.MultinomialNB(), \n",
      "                        naive_bayes.BernoulliNB(), \n",
      "                        linear_model.Perceptron(), \n",
      "                        linear_model.SGDClassifier(),\n",
      "                        linear_model.PassiveAggressiveClassifier()\n",
      "                        )\n",
      "\n",
      "# To be on the safe side\n",
      "for learner in incremental_learners:\n",
      "    assert hasattr(learner, 'partial_fit') == True\n",
      "print('All of the incremental learners implement partial fit')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "All of the incremental learners implement partial fit\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_all = np.asanyarray(np.unique(y))\n",
      "\n",
      "multinomial = naive_bayes.BernoulliNB()\n",
      "multinomial.partial_fit(X[:1000], y[:1000], y_all)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "multinomial.score(X[-1000:], y[-1000:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "0.57399999999999995"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's train some more data and see if that actually improves the score for the last 1000 observations in the dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "multinomial.partial_fit(X[1000:-1000], y[1000:-1000])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \n",
      "multinomial.score(X[-1000:], y[-1000:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "0.64300000000000002"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Indeed, it increased. Note that the last 1000 observations are not used at all by the classifier itself."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}